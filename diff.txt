diff --git a/analyzer/main.py b/analyzer/main.py
index d12850b..5225888 100644
--- a/analyzer/main.py
+++ b/analyzer/main.py
@@ -1,26 +1,37 @@
 from fastapi import FastAPI, HTTPException, UploadFile, File
+from typing import Dict, List, Any, Optional
 from .models.schemas import AnalysisRequest, Policy
 from .services import dependency_extractor, package_info, repo_health
 from .services.repo_health import GITHUB_TOKEN, GITLAB_TOKEN
+from core.models import Dependency
 
 # Initialize FastAPI app
 app = FastAPI()
 
 @app.post("/v1/analyze")
-def analyze(request: AnalysisRequest):
-    """
-    Analyze the provided manifest content to extract dependencies, fetch package info, and check repository health.
+def analyze(request: AnalysisRequest) -> Dict[str, List[Dict[str, Any]]]:
+    """Analyze manifest content to extract dependencies and check repository health.
+    
+    Extracts dependencies from the provided manifest content, fetches package information
+    from appropriate registries (PyPI/npm), and performs repository health checks for
+    supported platforms (GitHub/GitLab).
+    
     Args:
-        request (AnalysisRequest): The analysis request containing manifest content, type, and policy.
+        request: The analysis request containing manifest content, type, and policy.
+        
     Returns:
-        dict: Results for each dependency including package info and health check.
+        Dictionary containing a 'results' key with a list of analysis results for each
+        dependency. Each result includes dependency name, package info, and health data.
+        
+    Raises:
+        HTTPException: If the manifest type is not supported (status 400).
     """
     # 1. Extract dependencies from manifest content
     manifest_type = request.manifest_type.lower()
     content = request.manifest_content
 
     # Map manifest types to their respective extractor functions
-    extractor_map = {
+    extractor_map: Dict[str, Any] = {
         'requirements.txt': dependency_extractor.extract_requirements_txt_from_content,
         'package.json': dependency_extractor.extract_package_json_from_content,
         'pyproject.toml': dependency_extractor.extract_pyproject_toml_from_content,
@@ -33,8 +44,8 @@ def analyze(request: AnalysisRequest):
         raise HTTPException(status_code=400, detail=f"Unsupported manifest type: {manifest_type}")
 
     # Extract dependencies using the appropriate extractor
-    dependencies = extractor_map[manifest_type](content)
-    results = []
+    dependencies: List[Dependency] = extractor_map[manifest_type](content)
+    results: List[Dict[str, Any]] = []
 
     for dep in dependencies:
         # 2. Get package info and repo URL
@@ -115,17 +126,26 @@ def analyze(request: AnalysisRequest):
     return {"results": results}
 
 @app.post("/v1/analyze/file")
-def post_file(file: UploadFile = File(...)):
-    """
-    Analyze a manifest file uploaded by the user. Infers manifest type from filename and delegates to analyze().
+def post_file(file: UploadFile = File(...)) -> Dict[str, List[Dict[str, Any]]]:
+    """Analyze an uploaded manifest file.
+    
+    Automatically infers the manifest type from the filename and performs the same
+    analysis as the /v1/analyze endpoint. Uses default policy settings.
+    
     Args:
-        file (UploadFile): The uploaded manifest file.
+        file: The uploaded manifest file to analyze.
+        
     Returns:
-        dict: Analysis results for the uploaded file.
+        Dictionary containing analysis results for the uploaded file.
+        
+    Raises:
+        HTTPException: If the manifest type cannot be inferred from filename (status 400).
     """
     # Infer manifest type from filename
-    filename = file.filename.lower()
-    manifest_type_map = {
+    if file.filename is None:
+        raise HTTPException(status_code=400, detail="No filename provided")
+    filename: str = file.filename.lower()
+    manifest_type_map: Dict[str, str] = {
         "requirements.txt": "requirements.txt",
         "package.json": "package.json",
         "pyproject.toml": "pyproject.toml",
@@ -134,7 +154,7 @@ def post_file(file: UploadFile = File(...)):
         "poetry.lock": "poetry.lock"
     }
 
-    manifest_type = None
+    manifest_type: Optional[str] = None
     for ext, type_name in manifest_type_map.items():
         if filename.endswith(ext):
             manifest_type = type_name
@@ -145,7 +165,7 @@ def post_file(file: UploadFile = File(...)):
         raise HTTPException(status_code=400, detail=f"Could not infer manifest type from filename: {filename}")
 
     # Read file content and create default policy
-    content = file.file.read().decode("utf-8")
-    policy = Policy()
-    request = AnalysisRequest(manifest_content=content, manifest_type=manifest_type, policy=policy)
+    content: str = file.file.read().decode("utf-8")
+    policy: Policy = Policy()
+    request: AnalysisRequest = AnalysisRequest(manifest_content=content, manifest_type=manifest_type, policy=policy)
     return analyze(request)
\ No newline at end of file
diff --git a/analyzer/services/dependency_extractor.py b/analyzer/services/dependency_extractor.py
index 4d79447..8338d26 100644
--- a/analyzer/services/dependency_extractor.py
+++ b/analyzer/services/dependency_extractor.py
@@ -2,7 +2,7 @@ import re
 import json
 import toml
 import yaml
-from typing import List
+from typing import List, Dict, Any, Union
 from core.models import Dependency
 
 def extract_requirements_txt_from_content(content: str) -> List[Dependency]:
@@ -13,7 +13,7 @@ def extract_requirements_txt_from_content(content: str) -> List[Dependency]:
     Returns:
         List[Dependency]: List of extracted dependencies.
     """
-    dependencies = []
+    dependencies: List[Dependency] = []
     for line in content.splitlines():
         line = line.strip()
         if not line or line.startswith('#'):
@@ -35,8 +35,8 @@ def extract_package_json_from_content(content: str) -> List[Dependency]:
     Returns:
         List[Dependency]: List of extracted dependencies.
     """
-    dependencies = []
-    data = json.loads(content)
+    dependencies: List[Dependency] = []
+    data: Dict[str, Any] = json.loads(content)
     for section in ['dependencies', 'devDependencies']:
         for name, version in data.get(section, {}).items():
             dependencies.append(Dependency(name=name, version=version, source='npm', raw=f'{name}: {version}'))
@@ -50,12 +50,13 @@ def extract_pyproject_toml_from_content(content: str) -> List[Dependency]:
     Returns:
         List[Dependency]: List of extracted dependencies.
     """
-    dependencies = []
-    data = toml.loads(content)
-    poetry_deps = data.get('tool', {}).get('poetry', {}).get('dependencies', {})
+    dependencies: List[Dependency] = []
+    data: Dict[str, Any] = toml.loads(content)
+    poetry_deps: Dict[str, Union[str, Dict[str, Any]]] = data.get('tool', {}).get('poetry', {}).get('dependencies', {})
     for name, version in poetry_deps.items():
         if name.lower() == 'python':
             continue  # Skip the Python version itself
+        version_str: Union[str, None]
         if isinstance(version, dict):
             version_str = version.get('version')
         else:
@@ -71,8 +72,8 @@ def extract_environment_yml_from_content(content: str) -> List[Dependency]:
     Returns:
         List[Dependency]: List of extracted dependencies.
     """
-    dependencies = []
-    data = yaml.safe_load(content)
+    dependencies: List[Dependency] = []
+    data: Dict[str, Any] = yaml.safe_load(content)
     for dep in data.get('dependencies', []):
         if isinstance(dep, str):
             # Conda dependency
@@ -80,7 +81,8 @@ def extract_environment_yml_from_content(content: str) -> List[Dependency]:
             dependencies.append(Dependency(name=name.strip(), version='='.join(version) if version else None, source='conda', raw=dep))
         elif isinstance(dep, dict) and 'pip' in dep:
             # Pip dependencies inside environment.yml
-            for pip_dep in dep['pip']:
+            pip_deps: List[str] = dep['pip']
+            for pip_dep in pip_deps:
                 name, *version = pip_dep.split('==')
                 dependencies.append(Dependency(name=name.strip(), version=version[0] if version else None, source='pip', raw=pip_dep))
     return dependencies
@@ -93,13 +95,15 @@ def extract_poetry_lock_from_content(content: str) -> List[Dependency]:
     Returns:
         List[Dependency]: List of extracted dependencies.
     """
-    dependencies = []
+    dependencies: List[Dependency] = []
     import re as _re
     # Split the file into package blocks
-    packages = _re.split(r'\n\[\[package\]\]\n', content)
+    packages: List[str] = _re.split(r'\n\[\[package\]\]\n', content)
     for pkg in packages:
-        lines = pkg.strip().splitlines()
-        name = version = category = None
+        lines: List[str] = pkg.strip().splitlines()
+        name: Union[str, None] = None
+        version: Union[str, None] = None
+        category: Union[str, None] = None
         for line in lines:
             if line.startswith('name = '):
                 name = line.split('=', 1)[1].strip().strip('"')
diff --git a/analyzer/services/package_info.py b/analyzer/services/package_info.py
index fab3951..cbccbe6 100644
--- a/analyzer/services/package_info.py
+++ b/analyzer/services/package_info.py
@@ -1,9 +1,9 @@
 import re
 import requests
-from typing import Dict, Optional, Tuple
+from typing import Dict, Optional, Tuple, Any, List
 from urllib.parse import urlparse
 
-def get_library_info(library_name: str) -> Optional[Dict]:
+def get_library_info(library_name: str) -> Optional[Dict[str, Any]]:
     """
     Fetch package metadata from PyPI for a given library name.
     Args:
@@ -15,15 +15,16 @@ def get_library_info(library_name: str) -> Optional[Dict]:
     """
     if not re.match(r"^[a-zA-Z0-9_-]+$", library_name):
         raise ValueError("Invalid library name. Only alphanumeric characters, dashes, and underscores are allowed.")
-    url = f"https://pypi.org/pypi/{library_name}/json"
+    url: str = f"https://pypi.org/pypi/{library_name}/json"
     try:
-        response = requests.get(url)
+        response: requests.Response = requests.get(url)
         response.raise_for_status()
-        return response.json()
+        json_data: Dict[str, Any] = response.json()
+        return json_data
     except requests.exceptions.RequestException:
         return None
 
-def get_npm_info(package_name: str) -> Optional[Dict]:
+def get_npm_info(package_name: str) -> Optional[Dict[str, Any]]:
     """
     Fetch package metadata from npm registry for a given package name.
     Args:
@@ -35,11 +36,12 @@ def get_npm_info(package_name: str) -> Optional[Dict]:
     """
     if not re.match(r"^[a-zA-Z0-9_-]+$", package_name):
         raise ValueError("Invalid package name. Only alphanumeric characters, dashes, and underscores are allowed.")
-    url = f"https://registry.npmjs.org/{package_name}"
+    url: str = f"https://registry.npmjs.org/{package_name}"
     try:
-        response = requests.get(url)
+        response: requests.Response = requests.get(url)
         response.raise_for_status()
-        return response.json()
+        json_data: Dict[str, Any] = response.json()
+        return json_data
     except requests.exceptions.RequestException:
         return None
 
@@ -54,7 +56,7 @@ def parse_repo_url(url: str) -> Tuple[Optional[str], Optional[str], Optional[str
     if url.startswith('git+'):
         url = url[4:]
     parsed_url = urlparse(url)
-    path_parts = parsed_url.path.strip('/').split('/')
+    path_parts: List[str] = parsed_url.path.strip('/').split('/')
     if len(path_parts) >= 2:
         org = path_parts[0]
         repo = path_parts[1]
@@ -67,7 +69,7 @@ def parse_repo_url(url: str) -> Tuple[Optional[str], Optional[str], Optional[str
             return 'bitbucket', org, repo
     return None, None, None
 
-def extract_repo_info(info: Dict) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:
+def extract_repo_info(info: Dict[str, Any]) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:
     """
     Extract the repository URL and its platform/org/repo from PyPI project metadata.
     Args:
@@ -100,7 +102,7 @@ def extract_repo_info(info: Dict) -> Tuple[Optional[str], Optional[str], Optiona
                 return url, platform, org, repo
     return None, None, None, None
 
-def extract_npm_repo_info(info: Dict) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:
+def extract_npm_repo_info(info: Dict[str, Any]) -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:
     """
     Extract the repository URL and its platform/org/repo from npm package metadata.
     Args:
@@ -116,7 +118,7 @@ def extract_npm_repo_info(info: Dict) -> Tuple[Optional[str], Optional[str], Opt
     platform, org, repo = parse_repo_url(repo_url)
     return repo_url, platform, org, repo
 
-def get_latest_version_release_date(info: Dict) -> Optional[str]:
+def get_latest_version_release_date(info: Dict[str, Any]) -> Optional[str]:
     """
     Get the release date of the latest version from PyPI package metadata.
     Args:
@@ -132,4 +134,5 @@ def get_latest_version_release_date(info: Dict) -> Optional[str]:
     releases = info["releases"][latest_version]
     if not releases:
         return None
-    return releases[0].get("upload_time_iso_8601")
\ No newline at end of file
+    upload_time: Optional[str] = releases[0].get("upload_time_iso_8601")
+    return upload_time
\ No newline at end of file
diff --git a/analyzer/services/repo_health.py b/analyzer/services/repo_health.py
index d2e0629..e81130e 100644
--- a/analyzer/services/repo_health.py
+++ b/analyzer/services/repo_health.py
@@ -1,7 +1,8 @@
 import os
 import requests
 from datetime import datetime, timezone
-from typing import Optional
+from typing import Optional, Dict, Any, List
+from urllib.parse import quote
 from dotenv import load_dotenv
 from ..models.schemas import HealthCheckResult, Policy
 from ..utils.helpers import parse_iso8601_timestamp
@@ -34,7 +35,7 @@ def check_github_health(owner: str, repo: str, policy: Policy, token: Optional[s
     Returns:
         HealthCheckResult: The health check result for the repository.
     """
-    headers = {"Accept": "application/vnd.github.v3+json"}
+    headers: Dict[str, str] = {"Accept": "application/vnd.github.v3+json"}
     if token:
         headers["Authorization"] = f"token {token}"
     # Initialize result object
@@ -46,10 +47,10 @@ def check_github_health(owner: str, repo: str, policy: Policy, token: Optional[s
     )
     try:
         # Fetch repository metadata
-        repo_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}"
-        repo_response = requests.get(repo_url, headers=headers)
+        repo_url: str = f"{GITHUB_API_BASE}/repos/{owner}/{repo}"
+        repo_response: requests.Response = requests.get(repo_url, headers=headers)
         repo_response.raise_for_status()
-        repo_data = repo_response.json()
+        repo_data: Dict[str, Any] = repo_response.json()
         result.last_activity = repo_data.get("pushed_at")
         if result.last_activity:
             # Calculate days since last activity
@@ -62,18 +63,18 @@ def check_github_health(owner: str, repo: str, policy: Policy, token: Optional[s
             elif result.days_since_last_activity > 90:
                 result.warnings.append("Repository has been inactive for over 90 days")
         # Fetch open issues
-        issues_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/issues"
-        issues_response = requests.get(issues_url, headers=headers)
+        issues_url: str = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/issues"
+        issues_response: requests.Response = requests.get(issues_url, headers=headers)
         issues_response.raise_for_status()
         result.open_issues_count = len(issues_response.json())
         # Fetch stars and forks count
         result.stars_count = repo_data.get("stargazers_count", 0)
         result.forks_count = repo_data.get("forks_count", 0)
         # Check for README and LICENSE files in repo root
-        contents_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/contents"
-        contents_response = requests.get(contents_url, headers=headers)
+        contents_url: str = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/contents"
+        contents_response: requests.Response = requests.get(contents_url, headers=headers)
         if contents_response.status_code == 200:
-            contents = contents_response.json()
+            contents: List[Dict[str, Any]] = contents_response.json()
             result.has_readme = any(file["name"].lower() in [r.lower() for r in README_FILES] for file in contents)
             result.has_license = any(file["name"].lower() in [l.lower() for l in LICENSE_FILES] for file in contents)
             if policy.require_readme and not result.has_readme:
@@ -99,7 +100,7 @@ def check_gitlab_health(owner: str, repo: str, policy: Policy, token: Optional[s
     Returns:
         HealthCheckResult: The health check result for the repository.
     """
-    headers = {}
+    headers: Dict[str, str] = {}
     if token:
         headers["PRIVATE-TOKEN"] = token
     # Initialize result object
@@ -111,10 +112,10 @@ def check_gitlab_health(owner: str, repo: str, policy: Policy, token: Optional[s
     )
     try:
         # Fetch project metadata
-        project_url = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}"
-        project_response = requests.get(project_url, headers=headers)
+        project_url: str = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}"
+        project_response: requests.Response = requests.get(project_url, headers=headers)
         project_response.raise_for_status()
-        project_data = project_response.json()
+        project_data: Dict[str, Any] = project_response.json()
         result.last_activity = project_data.get("last_activity_at")
         if result.last_activity:
             # Calculate days since last activity
@@ -127,21 +128,21 @@ def check_gitlab_health(owner: str, repo: str, policy: Policy, token: Optional[s
             elif result.days_since_last_activity > 90:
                 result.warnings.append("Repository has been inactive for over 90 days")
         # Fetch open issues
-        issues_url = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}/issues"
-        issues_response = requests.get(issues_url, headers=headers)
+        issues_url: str = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}/issues"
+        issues_response: requests.Response = requests.get(issues_url, headers=headers)
         issues_response.raise_for_status()
         result.open_issues_count = len(issues_response.json())
         # Fetch stars and forks count
         result.stars_count = project_data.get("star_count", 0)
         result.forks_count = project_data.get("forks_count", 0)
         # Determine default branch for file checks
-        default_branch = project_data.get("default_branch", "master")
+        default_branch: str = project_data.get("default_branch", "master")
         # Check for README files
         result.has_readme = False
         for readme_name in README_FILES:
-            file_url = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}/repository/files/{requests.utils.quote(readme_name, safe='')}"
-            params = {"ref": default_branch}
-            file_response = requests.get(file_url, headers=headers, params=params)
+            file_url: str = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}/repository/files/{quote(readme_name, safe='')}"
+            params: Dict[str, str] = {"ref": default_branch}
+            file_response: requests.Response = requests.get(file_url, headers=headers, params=params)
             if file_response.status_code == 200:
                 result.has_readme = True
                 break
@@ -151,10 +152,10 @@ def check_gitlab_health(owner: str, repo: str, policy: Policy, token: Optional[s
         # Check for LICENSE files
         result.has_license = False
         for license_name in LICENSE_FILES:
-            file_url = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}/repository/files/{requests.utils.quote(license_name, safe='')}"
-            params = {"ref": default_branch}
-            file_response = requests.get(file_url, headers=headers, params=params)
-            if file_response.status_code == 200:
+            license_file_url: str = f"{GITLAB_API_BASE}/projects/{owner}%2F{repo}/repository/files/{quote(license_name, safe='')}"
+            license_params: Dict[str, str] = {"ref": default_branch}
+            license_file_response: requests.Response = requests.get(license_file_url, headers=headers, params=license_params)
+            if license_file_response.status_code == 200:
                 result.has_license = True
                 break
         if policy.require_license and not result.has_license:
diff --git a/extractor/cli.py b/extractor/cli.py
index 809f2a4..666f78f 100644
--- a/extractor/cli.py
+++ b/extractor/cli.py
@@ -1,16 +1,22 @@
 import typer
 import json
 from pathlib import Path
+from typing import List, Dict, Any, Optional
 from extractor.extractor.requirements_txt import extract_requirements_txt
 from extractor.extractor.environment_yml import extract_environment_yml
 from extractor.extractor.pyproject_toml import extract_pyproject_toml
 from extractor.extractor.package_json import extract_package_json
 from extractor.extractor.poetry_lock import extract_poetry_lock
+from core.models import Dependency
 
 app = typer.Typer(help="Vitalis - Dependency manifest extractor and analyzer")
 
-def _print_fallback_human_readable(deps_data):
-    """Print fallback extraction result in human-readable format"""
+def _print_fallback_human_readable(deps_data: List[Dict[str, Any]]) -> None:
+    """Print fallback extraction result in human-readable format.
+    
+    Args:
+        deps_data: List of dependency dictionaries to display.
+    """
     typer.echo("Basic Dependency Extraction")
     typer.echo("=" * 40)
     typer.echo(f"\nFound {len(deps_data)} dependencies:")
@@ -25,10 +31,24 @@ def _print_fallback_human_readable(deps_data):
 @app.command()
 def extract(
     file: Path = typer.Argument(..., help="Path to the manifest file"),
-    manifest_type: str = typer.Option(None, help="Type of manifest: requirements.txt, environment.yml, pyproject.toml, package.json, poetry.lock"),
+    manifest_type: Optional[str] = typer.Option(None, help="Type of manifest: requirements.txt, environment.yml, pyproject.toml, package.json, poetry.lock"),
     format: str = typer.Option("human", "--format", help="Output format: human or json (default: human)")
-):
-    """Extract dependencies from a manifest file"""
+) -> None:
+    """Extract dependencies from a manifest file.
+    
+    This command parses various manifest file formats and extracts dependency
+    information. If manifest_type is not specified, it will be inferred from
+    the filename.
+    
+    Args:
+        file: Path to the manifest file to process.
+        manifest_type: Type of manifest file. If None, will be inferred from filename.
+        format: Output format - either 'human' for readable output or 'json' for structured data.
+        
+    Raises:
+        typer.Exit: If file doesn't exist, manifest type cannot be inferred, or
+                   an unsupported manifest type is specified.
+    """
     if not file.exists():
         typer.echo(f"File not found: {file}", err=True)
         raise typer.Exit(1)
@@ -73,8 +93,11 @@ def extract(
         _print_fallback_human_readable(deps_data)
 
 @app.command()
-def health():
-    """Check the health of the vitalis CLI"""
+def health() -> None:
+    """Check the health of the vitalis CLI.
+    
+    Performs a basic health check to verify the CLI is functioning properly.
+    """
     typer.echo("Vitalis CLI is healthy!")
 
 if __name__ == "__main__":
diff --git a/extractor/extractor/environment_yml.py b/extractor/extractor/environment_yml.py
index 392a0b8..e7ee6c9 100644
--- a/extractor/extractor/environment_yml.py
+++ b/extractor/extractor/environment_yml.py
@@ -1,18 +1,35 @@
 import yaml
 from core.models import Dependency
-from typing import List
+from typing import List, Any, Dict, Union
 
 def extract_environment_yml(path: str) -> List[Dependency]:
-    dependencies = []
+    """Extract dependencies from a Conda environment.yml file.
+    
+    Parses a Conda environment.yml file and extracts both conda and pip dependencies.
+    Supports both string-format dependencies and pip sub-sections.
+    
+    Args:
+        path: Path to the environment.yml file.
+        
+    Returns:
+        List of Dependency objects parsed from the file.
+        
+    Raises:
+        FileNotFoundError: If the environment.yml file does not exist.
+        yaml.YAMLError: If the YAML file is malformed.
+        UnicodeDecodeError: If the file cannot be decoded as UTF-8.
+    """
+    dependencies: List[Dependency] = []
     with open(path, 'r', encoding='utf-8') as f:
-        data = yaml.safe_load(f)
+        data: Dict[str, Any] = yaml.safe_load(f)
     for dep in data.get('dependencies', []):
         if isinstance(dep, str):
             # Conda dependency
             name, *version = dep.split('=')
             dependencies.append(Dependency(name=name.strip(), version='='.join(version) if version else None, source='conda', raw=dep))
         elif isinstance(dep, dict) and 'pip' in dep:
-            for pip_dep in dep['pip']:
+            pip_deps: List[str] = dep['pip']
+            for pip_dep in pip_deps:
                 name, *version = pip_dep.split('==')
                 dependencies.append(Dependency(name=name.strip(), version=version[0] if version else None, source='pip', raw=pip_dep))
     return dependencies
\ No newline at end of file
diff --git a/extractor/extractor/package_json.py b/extractor/extractor/package_json.py
index 0842ac0..8e2fbdc 100644
--- a/extractor/extractor/package_json.py
+++ b/extractor/extractor/package_json.py
@@ -1,11 +1,27 @@
 import json
 from core.models import Dependency
-from typing import List
+from typing import List, Dict, Any
 
 def extract_package_json(path: str) -> List[Dependency]:
-    dependencies = []
+    """Extract dependencies from a package.json file.
+    
+    Parses a package.json file and extracts both regular dependencies and
+    development dependencies from the respective sections.
+    
+    Args:
+        path: Path to the package.json file.
+        
+    Returns:
+        List of Dependency objects parsed from the file.
+        
+    Raises:
+        FileNotFoundError: If the package.json file does not exist.
+        json.JSONDecodeError: If the JSON file is malformed.
+        UnicodeDecodeError: If the file cannot be decoded as UTF-8.
+    """
+    dependencies: List[Dependency] = []
     with open(path, 'r', encoding='utf-8') as f:
-        data = json.load(f)
+        data: Dict[str, Any] = json.load(f)
     for section in ['dependencies', 'devDependencies']:
         for name, version in data.get(section, {}).items():
             dependencies.append(Dependency(name=name, version=version, source='npm', raw=f'{name}: {version}'))
diff --git a/extractor/extractor/poetry_lock.py b/extractor/extractor/poetry_lock.py
index 424cbdf..ba2b960 100644
--- a/extractor/extractor/poetry_lock.py
+++ b/extractor/extractor/poetry_lock.py
@@ -1,16 +1,34 @@
 from core.models import Dependency
-from typing import List
+from typing import List, Optional
 import re
 
 def extract_poetry_lock(path: str) -> List[Dependency]:
-    dependencies = []
+    """Extract dependencies from a poetry.lock file.
+    
+    Parses a poetry.lock file by splitting it into package sections and
+    extracting name, version, and category information. Only includes
+    packages marked as 'main' category (production dependencies).
+    
+    Args:
+        path: Path to the poetry.lock file.
+        
+    Returns:
+        List of Dependency objects parsed from the file.
+        
+    Raises:
+        FileNotFoundError: If the poetry.lock file does not exist.
+        UnicodeDecodeError: If the file cannot be decoded as UTF-8.
+    """
+    dependencies: List[Dependency] = []
     with open(path, 'r', encoding='utf-8') as f:
-        content = f.read()
+        content: str = f.read()
     # Split into package sections
-    packages = re.split(r'\n\[\[package\]\]\n', content)
+    packages: List[str] = re.split(r'\n\[\[package\]\]\n', content)
     for pkg in packages:
-        lines = pkg.strip().splitlines()
-        name = version = category = None
+        lines: List[str] = pkg.strip().splitlines()
+        name: Optional[str] = None
+        version: Optional[str] = None
+        category: Optional[str] = None
         for line in lines:
             if line.startswith('name = '):
                 name = line.split('=', 1)[1].strip().strip('"')
diff --git a/extractor/extractor/pyproject_toml.py b/extractor/extractor/pyproject_toml.py
index 9e88c4f..147230a 100644
--- a/extractor/extractor/pyproject_toml.py
+++ b/extractor/extractor/pyproject_toml.py
@@ -1,14 +1,30 @@
 import toml
 from core.models import Dependency
-from typing import List
+from typing import List, Dict, Any, Union
 
 def extract_pyproject_toml(path: str) -> List[Dependency]:
-    dependencies = []
-    data = toml.load(path)
-    poetry_deps = data.get('tool', {}).get('poetry', {}).get('dependencies', {})
+    """Extract dependencies from a pyproject.toml file.
+    
+    Parses a pyproject.toml file and extracts Poetry dependencies from the
+    [tool.poetry.dependencies] section. Skips Python version requirements.
+    
+    Args:
+        path: Path to the pyproject.toml file.
+        
+    Returns:
+        List of Dependency objects parsed from the file.
+        
+    Raises:
+        FileNotFoundError: If the pyproject.toml file does not exist.
+        toml.TomlDecodeError: If the TOML file is malformed.
+    """
+    dependencies: List[Dependency] = []
+    data: Dict[str, Any] = toml.load(path)
+    poetry_deps: Dict[str, Union[str, Dict[str, Any]]] = data.get('tool', {}).get('poetry', {}).get('dependencies', {})
     for name, version in poetry_deps.items():
         if name.lower() == 'python':
             continue
+        version_str: Union[str, None]
         if isinstance(version, dict):
             version_str = version.get('version')
         else:
diff --git a/extractor/extractor/requirements_txt.py b/extractor/extractor/requirements_txt.py
index 5397b42..b14cbe6 100644
--- a/extractor/extractor/requirements_txt.py
+++ b/extractor/extractor/requirements_txt.py
@@ -1,15 +1,30 @@
 from core.models import Dependency
-from typing import List
+from typing import List, Optional
+import re
 
 def extract_requirements_txt(path: str) -> List[Dependency]:
-    dependencies = []
+    """Extract dependencies from a requirements.txt file.
+    
+    Parses a requirements.txt file and extracts package names and versions.
+    Supports various version specifiers like ==, >=, <=, ~=, >, <, =.
+    
+    Args:
+        path: Path to the requirements.txt file.
+        
+    Returns:
+        List of Dependency objects parsed from the file.
+        
+    Raises:
+        FileNotFoundError: If the requirements.txt file does not exist.
+        UnicodeDecodeError: If the file cannot be decoded as UTF-8.
+    """
+    dependencies: List[Dependency] = []
     with open(path, 'r', encoding='utf-8') as f:
         for line in f:
             line = line.strip()
             if not line or line.startswith('#'):
                 continue
             # Split on '==' or '>=' or '<=' or '~=' or '>' or '<' or '='
-            import re
             match = re.match(r'([^=<>~!]+)([=<>~!]+)(.+)', line)
             if match:
                 name = match.group(1).strip()
diff --git a/extractor/utils.py b/extractor/utils.py
index b2c9b6f..b879003 100644
--- a/extractor/utils.py
+++ b/extractor/utils.py
@@ -2,5 +2,18 @@ from pathlib import Path
 from typing import Union
 
 def read_file_text(path: Union[str, Path]) -> str:
+    """Read the entire contents of a text file.
+    
+    Args:
+        path: File path as string or Path object.
+        
+    Returns:
+        The complete file contents as a string.
+        
+    Raises:
+        FileNotFoundError: If the file does not exist.
+        UnicodeDecodeError: If the file cannot be decoded as UTF-8.
+        PermissionError: If there are insufficient permissions to read the file.
+    """
     with open(path, 'r', encoding='utf-8') as f:
         return f.read()
\ No newline at end of file
diff --git a/pyproject.toml b/pyproject.toml
index eabb4f9..57f7bfc 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -34,6 +34,12 @@ dev = [
     "build>=0.10.0",
     "twine>=4.0.0",
     "jsonschema>=4.0.0",
+    "mypy>=1.0.0",
+    "coverage>=7.0.0",
+    "types-toml>=0.10.0",
+    "types-PyYAML>=6.0.0",
+    "types-requests>=2.0.0",
+    "httpx>=0.24.0",
 ]
 
 [project.scripts]
diff --git a/tests/test_analyzer_main.py b/tests/test_analyzer_main.py
new file mode 100644
index 0000000..11f40d1
--- /dev/null
+++ b/tests/test_analyzer_main.py
@@ -0,0 +1,249 @@
+import pytest
+import json
+import tempfile
+import os
+import sys
+from unittest.mock import patch, Mock
+from fastapi.testclient import TestClient
+from io import BytesIO
+
+# Add the project root to the Python path
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
+from analyzer.main import app
+from analyzer.models.schemas import AnalysisRequest, Policy
+
+client = TestClient(app)
+
+
+class TestAnalyzerMain:
+    """Test FastAPI endpoints in analyzer main module"""
+
+    @patch('analyzer.services.package_info.get_library_info')
+    @patch('analyzer.services.repo_health.check_github_health')
+    def test_analyze_endpoint_requirements_txt(self, mock_health_check, mock_package_info):
+        """Test analyze endpoint with requirements.txt content"""
+        # Mock package info response
+        mock_package_info.return_value = {
+            "info": {
+                "summary": "Python HTTP library",
+                "version": "2.25.0"
+            },
+            "project_urls": {
+                "Source": "https://github.com/psf/requests"
+            }
+        }
+        
+        # Mock health check response
+        mock_health_result = Mock()
+        mock_health_result.dict.return_value = {
+            "repository_url": "https://github.com/psf/requests",
+            "platform": "github",
+            "is_healthy": True,
+            "warnings": [],
+            "errors": []
+        }
+        mock_health_check.return_value = mock_health_result
+
+        request_data = {
+            "manifest_content": "requests==2.25.0\ndjango>=3.2.0",
+            "manifest_type": "requirements.txt",
+            "policy": {
+                "max_inactive_days": 365,
+                "require_license": True,
+                "require_readme": True
+            }
+        }
+
+        response = client.post("/v1/analyze", json=request_data)
+
+        assert response.status_code == 200
+        data = response.json()
+        assert "results" in data
+        assert len(data["results"]) == 2
+        assert data["results"][0]["dependency"] == "requests"
+
+    def test_analyze_endpoint_unsupported_manifest(self):
+        """Test analyze endpoint with unsupported manifest type"""
+        request_data = {
+            "manifest_content": "some content",
+            "manifest_type": "unsupported.txt",
+            "policy": {}
+        }
+
+        response = client.post("/v1/analyze", json=request_data)
+
+        assert response.status_code == 400
+        assert "Unsupported manifest type" in response.json()["detail"]
+
+    @patch('analyzer.services.package_info.get_npm_info')
+    def test_analyze_endpoint_package_json(self, mock_npm_info):
+        """Test analyze endpoint with package.json content"""
+        # Mock npm info response
+        mock_npm_info.return_value = {
+            "description": "Fast, unopinionated web framework",
+            "dist-tags": {"latest": "4.17.1"},
+            "repository": {
+                "url": "git+https://github.com/expressjs/express.git"
+            }
+        }
+
+        request_data = {
+            "manifest_content": '{"dependencies": {"express": "^4.17.1"}}',
+            "manifest_type": "package.json",
+            "policy": {}
+        }
+
+        response = client.post("/v1/analyze", json=request_data)
+
+        assert response.status_code == 200
+        data = response.json()
+        assert "results" in data
+        assert len(data["results"]) == 1
+        assert data["results"][0]["dependency"] == "express"
+
+    def test_analyze_file_endpoint_requirements_txt(self):
+        """Test analyze file endpoint with requirements.txt file"""
+        # Create a temporary requirements.txt file
+        content = "requests==2.25.0\ndjango>=3.2.0"
+        file_data = BytesIO(content.encode('utf-8'))
+
+        with patch('analyzer.services.package_info.get_library_info') as mock_package_info:
+            mock_package_info.return_value = None  # Simulate package not found
+
+            response = client.post(
+                "/v1/analyze/file",
+                files={"file": ("requirements.txt", file_data, "text/plain")}
+            )
+
+            assert response.status_code == 200
+            data = response.json()
+            assert "results" in data
+            assert len(data["results"]) == 2
+
+    def test_analyze_file_endpoint_unsupported_filename(self):
+        """Test analyze file endpoint with unsupported filename"""
+        content = "some content"
+        file_data = BytesIO(content.encode('utf-8'))
+
+        response = client.post(
+            "/v1/analyze/file",
+            files={"file": ("unsupported.txt", file_data, "text/plain")}
+        )
+
+        assert response.status_code == 400
+        assert "Could not infer manifest type" in response.json()["detail"]
+
+    def test_analyze_file_endpoint_package_json(self):
+        """Test analyze file endpoint with package.json file"""
+        content = '{"dependencies": {"express": "^4.17.1"}}'
+        file_data = BytesIO(content.encode('utf-8'))
+
+        with patch('analyzer.services.package_info.get_npm_info') as mock_npm_info:
+            mock_npm_info.return_value = None  # Simulate package not found
+
+            response = client.post(
+                "/v1/analyze/file",
+                files={"file": ("package.json", file_data, "application/json")}
+            )
+
+            assert response.status_code == 200
+            data = response.json()
+            assert "results" in data
+            assert len(data["results"]) == 1
+
+    def test_analyze_file_endpoint_environment_yml(self):
+        """Test analyze file endpoint with environment.yml file"""
+        content = """name: test-env
+dependencies:
+  - python=3.9
+  - requests==2.25.0
+"""
+        file_data = BytesIO(content.encode('utf-8'))
+
+        with patch('analyzer.services.package_info.get_library_info') as mock_package_info:
+            mock_package_info.return_value = None
+
+            response = client.post(
+                "/v1/analyze/file",
+                files={"file": ("environment.yml", file_data, "text/yaml")}
+            )
+
+            assert response.status_code == 200
+            data = response.json()
+            assert "results" in data
+
+    def test_analyze_file_endpoint_pyproject_toml(self):
+        """Test analyze file endpoint with pyproject.toml file"""
+        content = """[tool.poetry.dependencies]
+python = "^3.9"
+requests = "^2.25.0"
+"""
+        file_data = BytesIO(content.encode('utf-8'))
+
+        with patch('analyzer.services.package_info.get_library_info') as mock_package_info:
+            mock_package_info.return_value = None
+
+            response = client.post(
+                "/v1/analyze/file",
+                files={"file": ("pyproject.toml", file_data, "text/plain")}
+            )
+
+            assert response.status_code == 200
+            data = response.json()
+            assert "results" in data
+
+    def test_analyze_file_endpoint_poetry_lock(self):
+        """Test analyze file endpoint with poetry.lock file"""
+        content = """[[package]]
+name = "requests"
+version = "2.25.0"
+category = "main"
+"""
+        file_data = BytesIO(content.encode('utf-8'))
+
+        with patch('analyzer.services.package_info.get_library_info') as mock_package_info:
+            mock_package_info.return_value = None
+
+            response = client.post(
+                "/v1/analyze/file",
+                files={"file": ("poetry.lock", file_data, "text/plain")}
+            )
+
+            assert response.status_code == 200
+            data = response.json()
+            assert "results" in data
+
+    @patch('analyzer.services.package_info.get_library_info')
+    def test_analyze_conda_package_not_found(self, mock_package_info):
+        """Test analyze endpoint with conda package not found in PyPI"""
+        mock_package_info.return_value = None
+
+        request_data = {
+            "manifest_content": "name: test\ndependencies:\n  - conda-package=1.0.0",
+            "manifest_type": "environment.yml",
+            "policy": {}
+        }
+
+        response = client.post("/v1/analyze", json=request_data)
+
+        assert response.status_code == 200
+        data = response.json()
+        assert "results" in data
+        assert len(data["results"]) == 1
+        assert data["results"][0]["error"] is True
+        assert "conda-only or system package" in data["results"][0]["message"]
+
+    def test_analyze_file_no_filename(self):
+        """Test analyze file endpoint with no filename"""
+        content = "requests==2.25.0"
+        file_data = BytesIO(content.encode('utf-8'))
+
+        # Create file upload without filename
+        response = client.post(
+            "/v1/analyze/file",
+            files={"file": (None, file_data, "text/plain")}
+        )
+
+        # FastAPI returns 422 for validation errors, not 400
+        assert response.status_code == 422
\ No newline at end of file
diff --git a/tests/test_analyzer_package_info_extended.py b/tests/test_analyzer_package_info_extended.py
new file mode 100644
index 0000000..44c6b9d
--- /dev/null
+++ b/tests/test_analyzer_package_info_extended.py
@@ -0,0 +1,208 @@
+import pytest
+import sys
+import os
+from unittest.mock import patch, Mock
+
+# Add the project root to the Python path
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
+from analyzer.services.package_info import (
+    get_library_info,
+    get_npm_info,
+    parse_repo_url,
+    extract_repo_info,
+    extract_npm_repo_info,
+    get_latest_version_release_date
+)
+
+
+class TestPackageInfoExtended:
+    """Extended tests for package info functionality"""
+
+    def test_get_npm_info_invalid_name(self):
+        """Test npm package info with invalid name"""
+        with pytest.raises(ValueError):
+            get_npm_info("invalid@name")
+
+    @patch('analyzer.services.package_info.requests.get')
+    def test_get_npm_info_failure(self, mock_get):
+        """Test failed npm package info retrieval"""
+        from requests.exceptions import RequestException
+        mock_get.side_effect = RequestException("Network error")
+
+        result = get_npm_info("nonexistent")
+
+        assert result is None
+
+    def test_parse_repo_url_git_prefix(self):
+        """Test parsing repository URL with git+ prefix"""
+        url = "git+https://github.com/user/repo.git"
+        platform, org, repo = parse_repo_url(url)
+
+        assert platform == "github"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_parse_repo_url_bitbucket(self):
+        """Test parsing Bitbucket repository URL"""
+        url = "https://bitbucket.org/user/repo"
+        platform, org, repo = parse_repo_url(url)
+
+        assert platform == "bitbucket"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_parse_repo_url_subdomain_github(self):
+        """Test parsing GitHub Enterprise subdomain URL"""
+        url = "https://github.example.com/user/repo"
+        platform, org, repo = parse_repo_url(url)
+
+        # The current implementation only recognizes exact github.com domains
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_parse_repo_url_subdomain_gitlab(self):
+        """Test parsing GitLab self-hosted subdomain URL"""
+        url = "https://gitlab.example.com/group/project"
+        platform, org, repo = parse_repo_url(url)
+
+        # The current implementation only recognizes exact gitlab.com domains
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_parse_repo_url_insufficient_path_parts(self):
+        """Test parsing URL with insufficient path parts"""
+        url = "https://github.com/user"
+        platform, org, repo = parse_repo_url(url)
+
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_extract_repo_info_no_project_urls(self):
+        """Test extracting repo info when project_urls is missing"""
+        info = {"name": "test-package"}
+
+        repo_url, platform, org, repo = extract_repo_info(info)
+
+        assert repo_url is None
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_extract_repo_info_secondary_types(self):
+        """Test extracting repo info using secondary URL types"""
+        info = {
+            "project_urls": {
+                "Documentation": "https://docs.example.com",
+                "Homepage": "https://github.com/user/repo",
+                "Bug Tracker": "https://github.com/user/repo/issues"
+            }
+        }
+
+        repo_url, platform, org, repo = extract_repo_info(info)
+
+        assert repo_url == "https://github.com/user/repo"
+        assert platform == "github"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_extract_repo_info_fallback_types(self):
+        """Test extracting repo info using fallback URL types"""
+        info = {
+            "project_urls": {
+                "Documentation": "https://docs.example.com",
+                "Bug Tracker": "https://github.com/user/repo/issues",
+                "Funding": "https://sponsor.example.com",
+                "Custom": "https://github.com/user/repo"
+            }
+        }
+
+        repo_url, platform, org, repo = extract_repo_info(info)
+
+        assert repo_url == "https://github.com/user/repo"
+        assert platform == "github"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_extract_repo_info_excluded_types_only(self):
+        """Test extracting repo info when only excluded URL types exist"""
+        info = {
+            "project_urls": {
+                "Funding": "https://sponsor.example.com",
+                "Donate": "https://donate.example.com",
+                "Documentation": "https://docs.example.com"
+            }
+        }
+
+        repo_url, platform, org, repo = extract_repo_info(info)
+
+        assert repo_url is None
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_extract_npm_repo_info_no_repository(self):
+        """Test extracting npm repo info when repository field is missing"""
+        info = {"name": "test-package"}
+
+        repo_url, platform, org, repo = extract_npm_repo_info(info)
+
+        assert repo_url is None
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_extract_npm_repo_info_no_url(self):
+        """Test extracting npm repo info when repository URL is missing"""
+        info = {
+            "repository": {
+                "type": "git"
+                # url field is missing
+            }
+        }
+
+        repo_url, platform, org, repo = extract_npm_repo_info(info)
+
+        assert repo_url is None
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_get_latest_version_release_date_no_info(self):
+        """Test getting release date when info is missing"""
+        result = get_latest_version_release_date({})
+
+        assert result is None
+
+    def test_get_latest_version_release_date_no_version(self):
+        """Test getting release date when version info is missing"""
+        info = {"releases": {}}
+
+        result = get_latest_version_release_date(info)
+
+        assert result is None
+
+    def test_get_latest_version_release_date_version_not_in_releases(self):
+        """Test getting release date when version not found in releases"""
+        info = {
+            "info": {"version": "2.0.0"},
+            "releases": {"1.0.0": [{"upload_time_iso_8601": "2021-01-01T12:00:00Z"}]}
+        }
+
+        result = get_latest_version_release_date(info)
+
+        assert result is None
+
+    def test_get_latest_version_release_date_empty_releases_list(self):
+        """Test getting release date when releases list is empty"""
+        info = {
+            "info": {"version": "1.0.0"},
+            "releases": {"1.0.0": []}
+        }
+
+        result = get_latest_version_release_date(info)
+
+        assert result is None
\ No newline at end of file
diff --git a/tests/test_analyzer_repo_health.py b/tests/test_analyzer_repo_health.py
new file mode 100644
index 0000000..cb3d7a1
--- /dev/null
+++ b/tests/test_analyzer_repo_health.py
@@ -0,0 +1,250 @@
+import pytest
+import sys
+import os
+from unittest.mock import patch, Mock
+from datetime import datetime, timezone
+
+# Add the project root to the Python path
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
+from analyzer.services.repo_health import check_github_health, check_gitlab_health
+from analyzer.models.schemas import Policy, HealthCheckResult
+
+
+class TestRepoHealth:
+    """Test repository health checking functionality"""
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_github_health_success(self, mock_get):
+        """Test successful GitHub health check"""
+        # Mock repository response
+        repo_response = Mock()
+        repo_response.raise_for_status.return_value = None
+        repo_response.json.return_value = {
+            "pushed_at": "2021-01-01T12:00:00Z",
+            "stargazers_count": 100,
+            "forks_count": 50
+        }
+        
+        # Mock issues response
+        issues_response = Mock()
+        issues_response.raise_for_status.return_value = None
+        issues_response.json.return_value = [{"id": 1}, {"id": 2}]  # 2 open issues
+        
+        # Mock contents response
+        contents_response = Mock()
+        contents_response.status_code = 200
+        contents_response.json.return_value = [
+            {"name": "README.md"},
+            {"name": "LICENSE"},
+            {"name": "main.py"}
+        ]
+        
+        mock_get.side_effect = [repo_response, issues_response, contents_response]
+        
+        policy = Policy(max_inactive_days=365, require_license=True, require_readme=True)
+        result = check_github_health("user", "repo", policy, token="test_token")
+        
+        assert result.repository_url == "https://github.com/user/repo"
+        assert result.platform == "github"
+        assert result.owner == "user"
+        assert result.repo_name == "repo"
+        assert result.last_activity == "2021-01-01T12:00:00Z"
+        assert result.open_issues_count == 2
+        assert result.stars_count == 100
+        assert result.forks_count == 50
+        assert result.has_readme is True
+        assert result.has_license is True
+        assert result.is_healthy is False  # Due to inactivity
+        assert len(result.warnings) > 0
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_github_health_network_error(self, mock_get):
+        """Test GitHub health check with network error"""
+        from requests.exceptions import RequestException
+        mock_get.side_effect = RequestException("Network error")
+        
+        policy = Policy()
+        result = check_github_health("user", "repo", policy)
+        
+        assert result.is_healthy is False
+        assert len(result.errors) > 0
+        assert "Error checking GitHub repository" in result.errors[0]
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_github_health_missing_files(self, mock_get):
+        """Test GitHub health check when README/LICENSE missing"""
+        # Mock repository response
+        repo_response = Mock()
+        repo_response.raise_for_status.return_value = None
+        repo_response.json.return_value = {
+            "pushed_at": "2024-01-01T12:00:00Z",  # Recent activity
+            "stargazers_count": 100,
+            "forks_count": 50
+        }
+        
+        # Mock issues response
+        issues_response = Mock()
+        issues_response.raise_for_status.return_value = None
+        issues_response.json.return_value = []
+        
+        # Mock contents response - no README or LICENSE
+        contents_response = Mock()
+        contents_response.status_code = 200
+        contents_response.json.return_value = [{"name": "main.py"}]
+        
+        mock_get.side_effect = [repo_response, issues_response, contents_response]
+        
+        policy = Policy(max_inactive_days=365, require_license=True, require_readme=True)
+        result = check_github_health("user", "repo", policy)
+        
+        assert result.has_readme is False
+        assert result.has_license is False
+        assert result.is_healthy is False
+        assert "No README file found" in result.warnings
+        assert "No LICENSE file found" in result.warnings
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_github_health_90_day_warning(self, mock_get):
+        """Test GitHub health check with 90 day inactivity warning"""
+        # Mock repository response with activity more than 90 but less than 365 days ago
+        from datetime import datetime, timezone
+        from analyzer.services.repo_health import parse_iso8601_timestamp
+        
+        # Calculate a date that's about 180 days ago
+        import datetime as dt
+        now = dt.datetime.now(dt.timezone.utc)
+        past_date = now - dt.timedelta(days=180)
+        past_date_str = past_date.strftime("%Y-%m-%dT%H:%M:%SZ")
+        
+        repo_response = Mock()
+        repo_response.raise_for_status.return_value = None
+        repo_response.json.return_value = {
+            "pushed_at": past_date_str,
+            "stargazers_count": 100,
+            "forks_count": 50
+        }
+        
+        # Mock issues response
+        issues_response = Mock()
+        issues_response.raise_for_status.return_value = None
+        issues_response.json.return_value = []
+        
+        # Mock contents response
+        contents_response = Mock()
+        contents_response.status_code = 200
+        contents_response.json.return_value = [
+            {"name": "README.md"},
+            {"name": "LICENSE"}
+        ]
+        
+        mock_get.side_effect = [repo_response, issues_response, contents_response]
+        
+        policy = Policy(max_inactive_days=365, require_license=False, require_readme=False)
+        result = check_github_health("user", "repo", policy)
+        
+        assert "Repository has been inactive for over 90 days" in result.warnings
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_gitlab_health_success(self, mock_get):
+        """Test successful GitLab health check"""
+        # Use a more recent date to ensure the repo is considered healthy
+        import datetime as dt
+        now = dt.datetime.now(dt.timezone.utc)
+        recent_date = now - dt.timedelta(days=30)  # 30 days ago
+        recent_date_str = recent_date.strftime("%Y-%m-%dT%H:%M:%SZ")
+        
+        # Mock project response
+        project_response = Mock()
+        project_response.raise_for_status.return_value = None
+        project_response.json.return_value = {
+            "last_activity_at": recent_date_str,
+            "star_count": 75,
+            "forks_count": 25,
+            "default_branch": "main"
+        }
+        
+        # Mock issues response
+        issues_response = Mock()
+        issues_response.raise_for_status.return_value = None
+        issues_response.json.return_value = [{"id": 1}]  # 1 open issue
+        
+        # Mock README file response
+        readme_response = Mock()
+        readme_response.status_code = 200
+        
+        # Mock LICENSE file response
+        license_response = Mock()
+        license_response.status_code = 200
+        
+        mock_get.side_effect = [
+            project_response, 
+            issues_response, 
+            readme_response,  # README.md check
+            license_response  # LICENSE check
+        ]
+        
+        policy = Policy(max_inactive_days=365, require_license=True, require_readme=True)
+        result = check_gitlab_health("group", "project", policy, token="test_token")
+        
+        assert result.repository_url == "https://gitlab.com/group/project"
+        assert result.platform == "gitlab"
+        assert result.owner == "group"
+        assert result.repo_name == "project"
+        assert result.last_activity == recent_date_str
+        assert result.open_issues_count == 1
+        assert result.stars_count == 75
+        assert result.forks_count == 25
+        assert result.has_readme is True
+        assert result.has_license is True
+        assert result.is_healthy is True
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_gitlab_health_missing_files(self, mock_get):
+        """Test GitLab health check when README/LICENSE missing"""
+        # Mock project response
+        project_response = Mock()
+        project_response.raise_for_status.return_value = None
+        project_response.json.return_value = {
+            "last_activity_at": "2024-01-01T12:00:00Z",
+            "star_count": 75,
+            "forks_count": 25,
+            "default_branch": "main"
+        }
+        
+        # Mock issues response
+        issues_response = Mock()
+        issues_response.raise_for_status.return_value = None
+        issues_response.json.return_value = []
+        
+        # Mock file responses - all return 404 (not found)
+        file_not_found_response = Mock()
+        file_not_found_response.status_code = 404
+        
+        # There are multiple README and LICENSE file checks, so mock many 404s
+        mock_get.side_effect = [
+            project_response, 
+            issues_response
+        ] + [file_not_found_response] * 20  # Many file checks
+        
+        policy = Policy(max_inactive_days=365, require_license=True, require_readme=True)
+        result = check_gitlab_health("group", "project", policy)
+        
+        assert result.has_readme is False
+        assert result.has_license is False
+        assert result.is_healthy is False
+        assert "No README file found" in result.warnings
+        assert "No LICENSE file found" in result.warnings
+
+    @patch('analyzer.services.repo_health.requests.get')
+    def test_check_gitlab_health_network_error(self, mock_get):
+        """Test GitLab health check with network error"""
+        from requests.exceptions import RequestException
+        mock_get.side_effect = RequestException("Network error")
+        
+        policy = Policy()
+        result = check_gitlab_health("group", "project", policy)
+        
+        assert result.is_healthy is False
+        assert len(result.errors) > 0
+        assert "Error checking GitLab repository" in result.errors[0]
\ No newline at end of file
diff --git a/tests/test_analyzer_services.py b/tests/test_analyzer_services.py
new file mode 100644
index 0000000..f403098
--- /dev/null
+++ b/tests/test_analyzer_services.py
@@ -0,0 +1,275 @@
+import pytest
+import json
+import tempfile
+import os
+import sys
+from unittest.mock import patch, Mock
+
+# Add the project root to the Python path
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
+from analyzer.services.dependency_extractor import (
+    extract_requirements_txt_from_content,
+    extract_package_json_from_content,
+    extract_pyproject_toml_from_content,
+    extract_environment_yml_from_content,
+    extract_poetry_lock_from_content
+)
+from analyzer.services.package_info import (
+    get_library_info,
+    get_npm_info,
+    parse_repo_url,
+    extract_repo_info,
+    extract_npm_repo_info,
+    get_latest_version_release_date
+)
+from analyzer.utils.helpers import parse_iso8601_timestamp
+from core.models import Dependency
+from datetime import datetime, timezone
+
+
+class TestDependencyExtractor:
+    """Test dependency extraction from content strings"""
+
+    def test_extract_requirements_txt_from_content(self):
+        """Test extracting requirements.txt from content string"""
+        content = "requests==2.25.0\ndjango>=3.2.0\n# comment\nflask"
+        result = extract_requirements_txt_from_content(content)
+
+        assert len(result) == 3
+        assert result[0].name == 'requests'
+        assert result[0].version == '2.25.0'
+        assert result[0].source == 'pypi'
+        assert result[1].name == 'django'
+        assert result[1].version == '3.2.0'
+        assert result[2].name == 'flask'
+        assert result[2].version is None
+
+    def test_extract_package_json_from_content(self):
+        """Test extracting package.json from content string"""
+        content = """{
+  "dependencies": {
+    "express": "^4.17.1",
+    "lodash": "^4.17.21"
+  },
+  "devDependencies": {
+    "mocha": "^8.3.2"
+  }
+}"""
+        result = extract_package_json_from_content(content)
+
+        assert len(result) == 3
+        assert result[0].name == 'express'
+        assert result[0].version == '^4.17.1'
+        assert result[0].source == 'npm'
+
+    def test_extract_pyproject_toml_from_content(self):
+        """Test extracting pyproject.toml from content string"""
+        content = """[tool.poetry.dependencies]
+python = "^3.9"
+requests = "^2.25.0"
+django = {version = "^3.2.0", extras = ["dev"]}
+"""
+        result = extract_pyproject_toml_from_content(content)
+
+        assert len(result) == 2  # python is skipped
+        assert result[0].name == 'requests'
+        assert result[0].version == '^2.25.0'
+        assert result[0].source == 'poetry'
+
+    def test_extract_environment_yml_from_content(self):
+        """Test extracting environment.yml from content string"""
+        content = """name: test-env
+dependencies:
+  - python=3.9
+  - numpy=1.20.0
+  - pip:
+    - requests==2.25.0
+"""
+        result = extract_environment_yml_from_content(content)
+
+        assert len(result) == 3
+        assert result[0].name == 'python'
+        assert result[0].source == 'conda'
+        assert result[2].name == 'requests'
+        assert result[2].source == 'pip'
+
+    def test_extract_poetry_lock_from_content(self):
+        """Test extracting poetry.lock from content string"""
+        content = """[[package]]
+name = "requests"
+version = "2.25.0"
+category = "main"
+
+[[package]]
+name = "pytest"
+version = "6.2.0"
+category = "dev"
+"""
+        result = extract_poetry_lock_from_content(content)
+
+        assert len(result) == 1  # only main category
+        assert result[0].name == 'requests'
+        assert result[0].version == '2.25.0'
+        assert result[0].source == 'poetry.lock'
+
+
+class TestPackageInfo:
+    """Test package information retrieval"""
+
+    @patch('analyzer.services.package_info.requests.get')
+    def test_get_library_info_success(self, mock_get):
+        """Test successful PyPI library info retrieval"""
+        mock_response = Mock()
+        mock_response.raise_for_status.return_value = None
+        mock_response.json.return_value = {"info": {"name": "requests", "version": "2.25.0"}}
+        mock_get.return_value = mock_response
+
+        result = get_library_info("requests")
+
+        assert result is not None
+        assert result["info"]["name"] == "requests"
+        mock_get.assert_called_once_with("https://pypi.org/pypi/requests/json")
+
+    @patch('analyzer.services.package_info.requests.get')
+    def test_get_library_info_failure(self, mock_get):
+        """Test failed PyPI library info retrieval"""
+        from requests.exceptions import RequestException
+        mock_get.side_effect = RequestException("Network error")
+
+        result = get_library_info("nonexistent")
+
+        assert result is None
+
+    def test_get_library_info_invalid_name(self):
+        """Test PyPI library info with invalid name"""
+        with pytest.raises(ValueError):
+            get_library_info("invalid@name")
+
+    @patch('analyzer.services.package_info.requests.get')
+    def test_get_npm_info_success(self, mock_get):
+        """Test successful npm package info retrieval"""
+        mock_response = Mock()
+        mock_response.raise_for_status.return_value = None
+        mock_response.json.return_value = {"name": "express", "version": "4.17.1"}
+        mock_get.return_value = mock_response
+
+        result = get_npm_info("express")
+
+        assert result is not None
+        assert result["name"] == "express"
+        mock_get.assert_called_once_with("https://registry.npmjs.org/express")
+
+    def test_parse_repo_url_github(self):
+        """Test parsing GitHub repository URL"""
+        url = "https://github.com/user/repo"
+        platform, org, repo = parse_repo_url(url)
+
+        assert platform == "github"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_parse_repo_url_gitlab(self):
+        """Test parsing GitLab repository URL"""
+        url = "https://gitlab.com/group/project.git"
+        platform, org, repo = parse_repo_url(url)
+
+        assert platform == "gitlab"
+        assert org == "group"
+        assert repo == "project"
+
+    def test_parse_repo_url_invalid(self):
+        """Test parsing invalid repository URL"""
+        url = "https://example.com/not/a/repo"
+        platform, org, repo = parse_repo_url(url)
+
+        assert platform is None
+        assert org is None
+        assert repo is None
+
+    def test_extract_repo_info(self):
+        """Test extracting repository info from PyPI project data"""
+        info = {
+            "project_urls": {
+                "Homepage": "https://example.com",
+                "Source": "https://github.com/user/repo",
+                "Bug Tracker": "https://github.com/user/repo/issues"
+            }
+        }
+
+        repo_url, platform, org, repo = extract_repo_info(info)
+
+        assert repo_url == "https://github.com/user/repo"
+        assert platform == "github"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_extract_npm_repo_info(self):
+        """Test extracting repository info from npm package data"""
+        info = {
+            "repository": {
+                "type": "git",
+                "url": "git+https://github.com/user/repo.git"
+            }
+        }
+
+        repo_url, platform, org, repo = extract_npm_repo_info(info)
+
+        assert repo_url == "git+https://github.com/user/repo.git"
+        assert platform == "github"
+        assert org == "user"
+        assert repo == "repo"
+
+    def test_get_latest_version_release_date(self):
+        """Test getting latest version release date"""
+        info = {
+            "info": {"version": "2.25.0"},
+            "releases": {
+                "2.25.0": [
+                    {"upload_time_iso_8601": "2021-01-01T12:00:00Z"}
+                ]
+            }
+        }
+
+        result = get_latest_version_release_date(info)
+
+        assert result == "2021-01-01T12:00:00Z"
+
+    def test_get_latest_version_release_date_no_releases(self):
+        """Test getting release date when no releases exist"""
+        info = {"info": {"version": "1.0.0"}, "releases": {}}
+
+        result = get_latest_version_release_date(info)
+
+        assert result is None
+
+
+class TestHelpers:
+    """Test utility helper functions"""
+
+    def test_parse_iso8601_timestamp_with_milliseconds(self):
+        """Test parsing ISO 8601 timestamp with milliseconds"""
+        timestamp = "2021-01-01T12:00:00.123Z"
+        result = parse_iso8601_timestamp(timestamp)
+
+        assert result.year == 2021
+        assert result.month == 1
+        assert result.day == 1
+        assert result.hour == 12
+        assert result.tzinfo == timezone.utc
+
+    def test_parse_iso8601_timestamp_without_milliseconds(self):
+        """Test parsing ISO 8601 timestamp without milliseconds"""
+        timestamp = "2021-01-01T12:00:00Z"
+        result = parse_iso8601_timestamp(timestamp)
+
+        assert result.year == 2021
+        assert result.month == 1
+        assert result.day == 1
+        assert result.hour == 12
+        assert result.tzinfo == timezone.utc
+
+    def test_parse_iso8601_timestamp_invalid(self):
+        """Test parsing invalid timestamp format"""
+        with pytest.raises(ValueError):
+            parse_iso8601_timestamp("invalid-timestamp")
\ No newline at end of file
diff --git a/tests/test_extractors.py b/tests/test_extractors.py
new file mode 100644
index 0000000..a995233
--- /dev/null
+++ b/tests/test_extractors.py
@@ -0,0 +1,212 @@
+import pytest
+import json
+import tempfile
+import os
+import sys
+
+# Add the project root to the Python path
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
+from extractor.extractor.requirements_txt import extract_requirements_txt
+from extractor.extractor.environment_yml import extract_environment_yml
+from extractor.extractor.pyproject_toml import extract_pyproject_toml
+from extractor.extractor.package_json import extract_package_json
+from extractor.extractor.poetry_lock import extract_poetry_lock
+from core.models import Dependency
+
+
+class TestRequirementsTxt:
+    """Test requirements.txt extraction"""
+
+    def test_extract_requirements_txt_with_versions(self):
+        """Test extracting requirements.txt with version specifiers"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'requirements.txt')
+            with open(test_file, 'w') as f:
+                f.write('requests==2.25.0\ndjango>=3.2.0\nflask~=2.0.0\n')
+
+            result = extract_requirements_txt(test_file)
+
+            assert len(result) == 3
+            assert result[0].name == 'requests'
+            assert result[0].version == '2.25.0'
+            assert result[0].source == 'pypi'
+            assert result[1].name == 'django'
+            assert result[1].version == '3.2.0'
+
+    def test_extract_requirements_txt_without_versions(self):
+        """Test extracting requirements.txt without version specifiers"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'requirements.txt')
+            with open(test_file, 'w') as f:
+                f.write('requests\ndjango\n')
+
+            result = extract_requirements_txt(test_file)
+
+            assert len(result) == 2
+            assert result[0].name == 'requests'
+            assert result[0].version is None
+            assert result[1].name == 'django'
+            assert result[1].version is None
+
+    def test_extract_requirements_txt_with_comments(self):
+        """Test extracting requirements.txt with comments and empty lines"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'requirements.txt')
+            with open(test_file, 'w') as f:
+                f.write('# This is a comment\nrequests==2.25.0\n\n# Another comment\ndjango>=3.2.0\n')
+
+            result = extract_requirements_txt(test_file)
+
+            assert len(result) == 2
+            assert result[0].name == 'requests'
+            assert result[1].name == 'django'
+
+
+class TestEnvironmentYml:
+    """Test environment.yml extraction"""
+
+    def test_extract_environment_yml_conda_deps(self):
+        """Test extracting conda dependencies from environment.yml"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'environment.yml')
+            with open(test_file, 'w') as f:
+                f.write("""name: test-env
+dependencies:
+  - python=3.9
+  - numpy=1.20.0
+  - pandas
+""")
+
+            result = extract_environment_yml(test_file)
+
+            assert len(result) == 3
+            assert result[0].name == 'python'
+            assert result[0].version == '3.9'
+            assert result[0].source == 'conda'
+            assert result[1].name == 'numpy'
+            assert result[1].version == '1.20.0'
+            assert result[2].name == 'pandas'
+            assert result[2].version is None
+
+    def test_extract_environment_yml_pip_deps(self):
+        """Test extracting pip dependencies from environment.yml"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'environment.yml')
+            with open(test_file, 'w') as f:
+                f.write("""name: test-env
+dependencies:
+  - python=3.9
+  - pip:
+    - requests==2.25.0
+    - django==3.2.0
+""")
+
+            result = extract_environment_yml(test_file)
+
+            assert len(result) == 3
+            assert result[0].name == 'python'
+            assert result[0].source == 'conda'
+            assert result[1].name == 'requests'
+            assert result[1].version == '2.25.0'
+            assert result[1].source == 'pip'
+            assert result[2].name == 'django'
+            assert result[2].version == '3.2.0'
+            assert result[2].source == 'pip'
+
+
+class TestPyprojectToml:
+    """Test pyproject.toml extraction"""
+
+    def test_extract_pyproject_toml_poetry_deps(self):
+        """Test extracting Poetry dependencies from pyproject.toml"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'pyproject.toml')
+            with open(test_file, 'w') as f:
+                f.write("""[tool.poetry]
+name = "test-project"
+version = "0.1.0"
+
+[tool.poetry.dependencies]
+python = "^3.9"
+requests = "^2.25.0"
+django = {version = "^3.2.0", extras = ["dev"]}
+""")
+
+            result = extract_pyproject_toml(test_file)
+
+            assert len(result) == 2  # python is skipped
+            assert result[0].name == 'requests'
+            assert result[0].version == '^2.25.0'
+            assert result[0].source == 'poetry'
+            assert result[1].name == 'django'
+            assert result[1].version == '^3.2.0'
+
+
+class TestPackageJson:
+    """Test package.json extraction"""
+
+    def test_extract_package_json_deps(self):
+        """Test extracting dependencies from package.json"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'package.json')
+            with open(test_file, 'w') as f:
+                f.write("""{
+  "name": "test-project",
+  "version": "1.0.0",
+  "dependencies": {
+    "express": "^4.17.1",
+    "lodash": "^4.17.21"
+  },
+  "devDependencies": {
+    "mocha": "^8.3.2"
+  }
+}""")
+
+            result = extract_package_json(test_file)
+
+            assert len(result) == 3
+            assert result[0].name == 'express'
+            assert result[0].version == '^4.17.1'
+            assert result[0].source == 'npm'
+            assert result[1].name == 'lodash'
+            assert result[1].version == '^4.17.21'
+            assert result[2].name == 'mocha'
+            assert result[2].version == '^8.3.2'
+
+
+class TestPoetryLock:
+    """Test poetry.lock extraction"""
+
+    def test_extract_poetry_lock_deps(self):
+        """Test extracting dependencies from poetry.lock"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'poetry.lock')
+            with open(test_file, 'w') as f:
+                f.write("""[[package]]
+name = "requests"
+version = "2.25.0"
+category = "main"
+description = "Python HTTP for Humans."
+
+[[package]]
+name = "pytest"
+version = "6.2.0"
+category = "dev"
+description = "pytest: simple powerful testing with Python"
+
+[[package]]
+name = "django"
+version = "3.2.0"
+category = "main"
+description = "Django web framework"
+""")
+
+            result = extract_poetry_lock(test_file)
+
+            assert len(result) == 2  # Only main category packages
+            assert result[0].name == 'requests'
+            assert result[0].version == '2.25.0'
+            assert result[0].source == 'poetry.lock'
+            assert result[1].name == 'django'
+            assert result[1].version == '3.2.0'
\ No newline at end of file
diff --git a/tests/test_utils.py b/tests/test_utils.py
new file mode 100644
index 0000000..8aad4f1
--- /dev/null
+++ b/tests/test_utils.py
@@ -0,0 +1,66 @@
+import pytest
+import tempfile
+import os
+import sys
+from pathlib import Path
+
+# Add the project root to the Python path
+sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+
+from extractor.utils import read_file_text
+
+
+class TestUtils:
+    """Test utility functions"""
+
+    def test_read_file_text_str_path(self):
+        """Test reading file with string path"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'test.txt')
+            test_content = "Hello, World!\nThis is a test file."
+            
+            with open(test_file, 'w', encoding='utf-8') as f:
+                f.write(test_content)
+
+            result = read_file_text(test_file)
+            assert result == test_content
+
+    def test_read_file_text_path_object(self):
+        """Test reading file with Path object"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = Path(temp_dir) / 'test.txt'
+            test_content = "Hello, World!\nThis is a test file."
+            
+            with open(test_file, 'w', encoding='utf-8') as f:
+                f.write(test_content)
+
+            result = read_file_text(test_file)
+            assert result == test_content
+
+    def test_read_file_text_utf8_encoding(self):
+        """Test reading file with UTF-8 encoding"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'test.txt')
+            test_content = "Hello, 世界! 🌍"
+            
+            with open(test_file, 'w', encoding='utf-8') as f:
+                f.write(test_content)
+
+            result = read_file_text(test_file)
+            assert result == test_content
+
+    def test_read_file_text_empty_file(self):
+        """Test reading empty file"""
+        with tempfile.TemporaryDirectory() as temp_dir:
+            test_file = os.path.join(temp_dir, 'empty.txt')
+            
+            with open(test_file, 'w', encoding='utf-8') as f:
+                pass  # Create empty file
+
+            result = read_file_text(test_file)
+            assert result == ""
+
+    def test_read_file_text_file_not_found(self):
+        """Test reading non-existent file raises FileNotFoundError"""
+        with pytest.raises(FileNotFoundError):
+            read_file_text("/non/existent/file.txt")
\ No newline at end of file
